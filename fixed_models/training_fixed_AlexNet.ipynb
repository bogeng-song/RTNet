{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pyro-ppl==0.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from IPython import display\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "\n",
    "AlexTransform = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('mnist-data/', train=True, download=True, transform=AlexTransform),\n",
    "        batch_size=500, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('mnist-data/', train=False, download=True, transform=AlexTransform),\n",
    "        batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet\n",
    "class alexnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        out = F.relu(self.fc1(out))  # 256*6*6 -> 4096\n",
    "        out = F.dropout(out, 0.5)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.dropout(out, 0.5)\n",
    "        out = self.fc3(out)\n",
    "\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = alexnet().to(device)\n",
    "optimizer = optim.Adam(cnn.parameters())\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hyper parameters\n",
    "img_size = 28 * 28\n",
    "hidden_layer_size = 1024\n",
    "num_classes = 10\n",
    "net = alexnet().to(device)\n",
    "# softmax\n",
    "log_softmax = nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 15\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # gives batch data, normalize x when iterate train_loader\n",
    "        b_x = Variable(images).to(device)   # batch x\n",
    "        b_y = Variable(labels).to(device)   # batch y\n",
    "        output = cnn(b_x)\n",
    "        loss = loss_func(output b_y)\n",
    "        optimizer.zero_grad() # clear gradients for this training step\n",
    "        loss.backward() # backpropagation, compute gradients\n",
    "        optimizer.step() # apply gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cnn, train_loader, epoch, num_epochs):\n",
    "    \n",
    "    cnn.train()\n",
    "        \n",
    "    # Train the model\n",
    "    total_step = len(train_loader)\n",
    "        \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # gives batch data, normalize x when iterate train_loader\n",
    "        b_x = Variable(images).to(device)   # batch x\n",
    "        b_y = Variable(labels).to(device)   # batch y\n",
    "        output = cnn(b_x)\n",
    "        loss = loss_func(output b_y)\n",
    "        optimizer.zero_grad() # clear gradients for this training step\n",
    "        loss.backward() # backpropagation, compute gradients\n",
    "        optimizer.step() # apply gradients\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch, num_epochs, i + 1, total_step, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(noise=0):\n",
    "\n",
    "    # Test the model\n",
    "    cnn.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        i = 0\n",
    "        soft_out1 = torch.zeros((10000,10))\n",
    "\n",
    "\n",
    "        for images, labels in test_loader:\n",
    "            images = images + noise * torch.rand(images.shape)\n",
    "            test_output = cnn(images.to(device))\n",
    "            soft_out1[i*batch_size:(i+1)*batch_size,:] = test_output\n",
    "            pred_y1 = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy1 = (pred_y1 == labels.to(device)).sum().item() / float(labels.to(device).size(0))\n",
    "\n",
    "            i = i + 1\n",
    "\n",
    "        print('Test Accuracy of the layer1 on the 10000 test images: %.2f' % accuracy1)\n",
    "\n",
    "\n",
    "    return soft_out1.cpu().numpy()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
